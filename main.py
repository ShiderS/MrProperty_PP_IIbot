import asyncio
import os

import base64
from openai import AsyncOpenAI
from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import CommandStart
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from aiogram.types import Message, FSInputFile, BufferedInputFile
from docx import Document

from config import TG_TOKEN, OPENAI_API_KEY, DB_NAME, TEMP_IMAGE_FOLDER, TEMP_DOC_FOLDER, OPENAI_VISION_MODEL
from data import db_session
from data.user import User

bot = Bot(token=TG_TOKEN)
dp = Dispatcher()

openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)


class ImageProcessing(StatesGroup):
    waiting_for_images = State()

def ensure_dir_exists(dir_path):
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

# async def get_qwen_text_from_image(image_path: str):
#     messages = [{
#         "role": "user",
#         "content": [
#             {"image": f"file://{os.path.abspath(image_path)}"},
#             {"text": "–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–æ–Ω—Å–ø–µ–∫—Ç–∞. –°–æ—Ö—Ä–∞–Ω–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ."}
#         ]
#     }]
#     try:
#         logging.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Qwen API –¥–ª—è —Ñ–∞–π–ª–∞: {image_path}")
#         response = await dashscope.MultiModalConversation.aCall(
#             model='qwen-vl-plus',
#             messages=messages
#         )
#
#         if response.status_code == HTTPStatus.OK:
#             logging.info(f"Qwen API –æ—Ç–≤–µ—Ç–∏–ª —É—Å–ø–µ—à–Ω–æ –¥–ª—è —Ñ–∞–π–ª–∞: {image_path}")
#             content = response.output.choices[0].message.content
#             if isinstance(content, list) and len(content) > 0 and 'text' in content[0]:
#                 return content[0]['text'].strip()
#             else:
#                 logging.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Qwen: {response}")
#                 return None
#         else:
#             logging.error(f'–û—à–∏–±–∫–∞ Qwen API: –ö–æ–¥={response.code}, –°–æ–æ–±—â–µ–Ω–∏–µ={response.message}, RequestId={response.request_id}')
#             return None
#
#     except Exception as e:
#         logging.exception(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Qwen API –¥–ª—è {image_path}: {e}")
#         return None


# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π ---
def image_to_base64(image_path: str):
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        return None

async def get_openai_text_from_image(image_path: str):
    base64_image = image_to_base64(image_path)
    if not base64_image:
        return None

    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "input_text", "text": "–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞. –ü–æ—Å—Ç–∞—Ä–∞–π—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∞–±–∑–∞—Ü—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫, –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ."
                },
                {
                    "type": "input_image",
                    "image_url": f"data:image/jpeg;base64,{base64_image}"
                }
            ]
        }
    ]

    try:
        response = await openai_client.chat.completions.create(
            model=OPENAI_VISION_MODEL,
            messages=messages,
        )


        if response.choices and response.choices[0].message and response.choices[0].message.content:
            extracted_text = response.choices[0].message.content.strip()
            return extracted_text
        else:
            return None
    except Exception as e:
        return "[–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è]"


def create_word_document(text: str, filename: str):
    try:
        document = Document()
        for paragraph_text in text.split('\n'):
             if paragraph_text.strip():
                 document.add_paragraph(paragraph_text)
             else:
                 document.add_paragraph()

        ensure_dir_exists(TEMP_DOC_FOLDER)
        doc_path = os.path.join(TEMP_DOC_FOLDER, filename)
        document.save(doc_path)
        return doc_path
    except Exception as e:
        return None

@dp.message(CommandStart())
async def cmd_start(message: Message, state: FSMContext):
    await state.clear()
    session = db_session.create_session()
    try:
        user = session.query(User).filter(User.id == message.from_user.id).first()
        if not user:
            user = User(
                id=message.from_user.id,
                full_name=message.from_user.full_name,
                tg_name=message.from_user.username
            )
            session.add(user)
            session.commit()
        else:
            await message.answer(
                f"–ü—Ä–∏–≤–µ—Ç, {message.from_user.first_name}! üëã\n\n"
                "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –æ–¥–Ω—É –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞—Ä—Ç–∏–Ω–æ–∫ —Ç–≤–æ–µ–≥–æ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞. "
                "–ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—à—å, –Ω–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É '–ì–æ—Ç–æ–≤–æ ‚úÖ' –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å –∫–æ–º–∞–Ω–¥—É /done, "
                "–∏ —è –ø–µ—Ä–µ–≤–µ–¥—É –∏—Ö –≤ —Ç–µ–∫—Å—Ç –∏ –ø—Ä–∏—à–ª—é Word-—Ñ–∞–π–ª."
        )
        await state.set_state(ImageProcessing.waiting_for_images)
        await state.update_data(image_files=[])
    except:
        pass

@dp.message(ImageProcessing.waiting_for_images, F.photo)
async def handle_photos(message: Message, state: FSMContext):
    if not message.photo:
        await message.reply("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
        return

    photo = message.photo[-1]
    file_id = photo.file_id

    user_data = await state.get_data()
    image_files = user_data.get("image_files", [])

    image_files.append(file_id)

    await state.update_data(image_files=image_files)


    keyboard = types.InlineKeyboardMarkup(inline_keyboard=[
        [types.InlineKeyboardButton(text="–ì–æ—Ç–æ–≤–æ ‚úÖ", callback_data="process_images")]
    ])


    try:
        await message.reply(
        f"–§–æ—Ç–æ {len(image_files)} –ø—Ä–∏–Ω—è—Ç–æ! üëç –û—Ç–ø—Ä–∞–≤–ª—è–π –µ—â–µ –∏–ª–∏ –Ω–∞–∂–º–∏ '–ì–æ—Ç–æ–≤–æ ‚úÖ'.",
        reply_markup=keyboard
        )
    except Exception as e:
              await message.reply(
                 f"–§–æ—Ç–æ {len(image_files)} –ø—Ä–∏–Ω—è—Ç–æ! üëç –û—Ç–ø—Ä–∞–≤–ª—è–π –µ—â–µ –∏–ª–∏ –Ω–∞–∂–º–∏ '–ì–æ—Ç–æ–≤–æ ‚úÖ'.",
                 reply_markup=keyboard
             )


@dp.message(ImageProcessing.waiting_for_images, F.text == "/done")
async def handle_done_command(message: Message, state: FSMContext):
    await process_uploaded_images(message, state)


@dp.callback_query(ImageProcessing.waiting_for_images, F.data == "process_images")
async def handle_done_button(callback: types.CallbackQuery, state: FSMContext):
    await callback.answer("–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
    await process_uploaded_images(callback.message, state, is_callback=True)


async def process_uploaded_images(message_or_callback_message: Message, state: FSMContext, is_callback: bool = False):
    user_data = await state.get_data()
    image_files = user_data.get("image_files", [])

    if not image_files:
        await message_or_callback_message.answer("–¢—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–∏–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∏ –ø–æ—Ç–æ–º –Ω–∞–∂–º–∏ '–ì–æ—Ç–æ–≤–æ ‚úÖ'.")
        return

    await state.clear()

    processing_message = await message_or_callback_message.answer(f"–ü–æ–ª—É—á–µ–Ω–æ {len(image_files)} —Ñ–æ—Ç–æ. –ù–∞—á–∏–Ω–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞... üß†")

    all_extracted_text = []
    temp_files_to_delete = []
    ensure_dir_exists(TEMP_IMAGE_FOLDER)

    for i, file_id in enumerate(image_files):
        try:
            await processing_message.edit_text(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–æ—Ç–æ {i+1} –∏–∑ {len(image_files)}...")
            file_info = await bot.get_file(file_id)
            file_path = file_info.file_path
            temp_image_path = os.path.join(TEMP_IMAGE_FOLDER, f"{message_or_callback_message.chat.id}_{file_id}.jpeg")
            temp_files_to_delete.append(temp_image_path)

            await bot.download_file(file_path, temp_image_path)

            extracted_text = await get_openai_text_from_image(temp_image_path)

            if extracted_text:
                all_extracted_text.append(extracted_text)
            else:
                all_extracted_text.append(f"[–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ {i+1}]")
        except Exception as e:
            all_extracted_text.append(f"[–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i+1}]")
        finally:
            pass

    await processing_message.edit_text("–¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω. –°–æ–∑–¥–∞—é Word –¥–æ–∫—É–º–µ–Ω—Ç... üìÑ")
    final_text = "\n\n---\n\n".join(all_extracted_text)

    doc_filename = f"konspekt_{message_or_callback_message.chat.id}_{message_or_callback_message.message_id}.docx"
    doc_path = create_word_document(final_text, doc_filename)

    if doc_path:
        try:
            input_file = FSInputFile(doc_path, filename=f"–¢–≤–æ–π_–∫–æ–Ω—Å–ø–µ–∫—Ç_{message_or_callback_message.chat.id}.docx")
            await message_or_callback_message.answer_document(input_file, caption="–ì–æ—Ç–æ–≤–æ! –í–æ—Ç —Ç–≤–æ–π –∫–æ–Ω—Å–ø–µ–∫—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Word.")
            try:
                os.remove(doc_path)
            except OSError as e:
                pass

        except Exception as e:
            await message_or_callback_message.answer("–ù–µ —Å–º–æ–≥ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å Word —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑ –ø–æ–∑–∂–µ.")
        finally:
             await processing_message.delete() # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–°–æ–∑–¥–∞—é Word..."

    else:
        await processing_message.edit_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Word —Ñ–∞–π–ª. –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ–∫—Å—Ç –∫–∞–∫ —Å–æ–æ–±—â–µ–Ω–∏–µ:")
        max_length = 4096
        for i in range(0, len(final_text), max_length):
            await message_or_callback_message.answer(final_text[i:i + max_length])

    for f_path in temp_files_to_delete:
        try:
            os.remove(f_path)
        except OSError as e:
            pass

@dp.message(ImageProcessing.waiting_for_images)
async def handle_other_messages_while_waiting(message: Message, state: FSMContext):
    await message.reply("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ñ–æ—Ç–æ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞ –∏–ª–∏ –Ω–∞–∂–º–∏ '–ì–æ—Ç–æ–≤–æ ‚úÖ' / –æ—Ç–ø—Ä–∞–≤—å /done, –µ—Å–ª–∏ –∑–∞–∫–æ–Ω—á–∏–ª.")


@dp.message()
async def handle_unknown_messages(message: Message, state: FSMContext):
    current_state = await state.get_state()
    if current_state is None:
        await message.reply("–Ø –Ω–µ –ø–æ–Ω–∏–º–∞—é —ç—Ç—É –∫–æ–º–∞–Ω–¥—É. –ò—Å–ø–æ–ª—å–∑—É–π /start, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")


# --- –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ---
async def main():
    db_session.global_init(DB_NAME)
    ensure_dir_exists(TEMP_IMAGE_FOLDER)
    ensure_dir_exists(TEMP_DOC_FOLDER)

    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())